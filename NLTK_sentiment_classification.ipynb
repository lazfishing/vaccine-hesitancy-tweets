{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1378212405470240771</td>\n",
       "      <td>current day rolling average exactly year ago n...</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1378170862151598080</td>\n",
       "      <td>racist nyc demands papers order get vaccine li...</td>\n",
       "      <td>anti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1272934425601466371</td>\n",
       "      <td>orange dictator said companies competing creat...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1357599878390677506</td>\n",
       "      <td>coronavirus update new york city chinatown bus...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1357555015095709698</td>\n",
       "      <td>coming soon vaccine passport via covid vaccina...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0  1378212405470240771  current day rolling average exactly year ago n...   \n",
       "1  1378170862151598080  racist nyc demands papers order get vaccine li...   \n",
       "2  1272934425601466371  orange dictator said companies competing creat...   \n",
       "3  1357599878390677506  coronavirus update new york city chinatown bus...   \n",
       "4  1357555015095709698  coming soon vaccine passport via covid vaccina...   \n",
       "\n",
       "     label  \n",
       "0      pro  \n",
       "1     anti  \n",
       "2  neutral  \n",
       "3  neutral  \n",
       "4  neutral  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_preprocessed.csv',index_col=0)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pro count: 582\n",
      "anti count: 96\n",
      "neutral count: 892\n"
     ]
    }
   ],
   "source": [
    "for label in ['pro','anti','neutral']:\n",
    "    print(label,'count:',len(df[df.label==label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.224, 'neu': 0.691, 'pos': 0.085, 'compound': -0.5277}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "sia.polarity_scores(df.text.iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = []\n",
    "negative_words = []\n",
    "neutral_words = []\n",
    "\n",
    "pos_word_list = [word.split() for word in df['text'][df.label=='pro']]\n",
    "neg_word_list = [word.split() for word in df['text'][df.label=='anti']]\n",
    "neu_word_list = [word.split() for word in df['text'][df.label=='neutral']]\n",
    "\n",
    "for wordlist in pos_word_list:\n",
    "    positive_words.extend(wordlist)\n",
    "\n",
    "for wordlist in neg_word_list:\n",
    "    negative_words.extend(wordlist)\n",
    "\n",
    "for wordlist in neu_word_list:\n",
    "    neutral_words.extend(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_fd = nltk.FreqDist(positive_words)\n",
    "negative_fd = nltk.FreqDist(negative_words)\n",
    "neutral_fd = nltk.FreqDist(neutral_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_set = set(positive_fd).intersection(negative_fd).intersection(neutral_fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in common_set:\n",
    "    del positive_fd[word]\n",
    "    del negative_fd[word]\n",
    "    del neutral_fd[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_positive = {word for word, count in positive_fd.most_common(100)}\n",
    "top_100_negative = {word for word, count in negative_fd.most_common(100)}\n",
    "top_100_neutral = {word for word, count in neutral_fd.most_common(100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'access',\n",
       " 'age',\n",
       " 'aid',\n",
       " 'am',\n",
       " 'apply',\n",
       " 'appointments',\n",
       " 'appreciation',\n",
       " 'appts',\n",
       " 'april',\n",
       " 'army',\n",
       " 'bronx',\n",
       " 'brooklyn',\n",
       " 'care',\n",
       " 'citywide',\n",
       " 'clich',\n",
       " 'conditions',\n",
       " 'corps',\n",
       " 'country',\n",
       " 'cvs',\n",
       " 'dining',\n",
       " 'efforts',\n",
       " 'eligibility',\n",
       " 'every',\n",
       " 'expansion',\n",
       " 'experience',\n",
       " 'faced',\n",
       " 'fast',\n",
       " 'food',\n",
       " 'goes',\n",
       " 'government',\n",
       " 'guard',\n",
       " 'ha',\n",
       " 'help',\n",
       " 'high',\n",
       " 'hiring',\n",
       " 'hosted',\n",
       " 'immediately',\n",
       " 'important',\n",
       " 'incarcerated',\n",
       " 'infected',\n",
       " 'j',\n",
       " 'k',\n",
       " 'let',\n",
       " 'life',\n",
       " 'live',\n",
       " 'lot',\n",
       " 'major',\n",
       " 'mass',\n",
       " 'massively',\n",
       " 'millions',\n",
       " 'monday',\n",
       " 'month',\n",
       " 'national',\n",
       " 'neighborhoods',\n",
       " 'ny',\n",
       " 'nycvaccineforall',\n",
       " 'nyers',\n",
       " 'older',\n",
       " 'open',\n",
       " 'opening',\n",
       " 'operation',\n",
       " 'outbreak',\n",
       " 'part',\n",
       " 'perfection',\n",
       " 'pharmacies',\n",
       " 'pm',\n",
       " 'positions',\n",
       " 'protect',\n",
       " 'ramp',\n",
       " 'required',\n",
       " 'rite',\n",
       " 'schedule',\n",
       " 'scheduling',\n",
       " 'seniors',\n",
       " 'service',\n",
       " 'show',\n",
       " 'sign',\n",
       " 'silk',\n",
       " 'site',\n",
       " 'sites',\n",
       " 'smallpox',\n",
       " 'smooth',\n",
       " 'sorry',\n",
       " 'st',\n",
       " 'stadium',\n",
       " 'staff',\n",
       " 'start',\n",
       " 'summer',\n",
       " 'supply',\n",
       " 'teachers',\n",
       " 'terrifying',\n",
       " 'thank',\n",
       " 'twitter',\n",
       " 'underlying',\n",
       " 'vaccinating',\n",
       " 'vax',\n",
       " 'visit',\n",
       " 'walgreens',\n",
       " 'wants',\n",
       " 'yankee'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_100_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to add sentiment features for each tweet to support classification later on\n",
    "# in addition to NLTK polarity scores...\n",
    "# we use the number of unique negative, positive, neutral words from our hand labelling\n",
    "\n",
    "def extract_features(text):\n",
    "    features = dict()\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    neu_count = 0\n",
    "    compound_scores = list()\n",
    "    positive_scores = list()\n",
    "    negative_scores = list()\n",
    "    neutral_scores = list()\n",
    "\n",
    "    for sentence in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sentence):\n",
    "            if word.lower() in top_100_positive:\n",
    "                pos_count += 1\n",
    "            elif word.lower() in top_100_negative:\n",
    "                neg_count += 1\n",
    "            elif word.lower() in top_100_neutral:\n",
    "                neu_count += 1\n",
    "        compound_scores.append(sia.polarity_scores(sentence)[\"compound\"])\n",
    "        positive_scores.append(sia.polarity_scores(sentence)[\"pos\"])\n",
    "        negative_scores.append(sia.polarity_scores(sentence)[\"neg\"])\n",
    "        neutral_scores.append(sia.polarity_scores(sentence)[\"neu\"])\n",
    "\n",
    "    # Adding 1 to the final compound score to always have positive numbers\n",
    "    features[\"mean_compound\"] = np.mean(compound_scores) + 1\n",
    "    features[\"mean_positive\"] = np.mean(positive_scores)\n",
    "    features[\"mean_negative\"] = np.mean(negative_scores)\n",
    "    features[\"mean_neutral\"] = np.mean(neutral_scores)\n",
    "    features[\"positive_words\"] = pos_count\n",
    "    features[\"negative_words\"] = neg_count\n",
    "    features[\"neutral_words\"] = neu_count\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_compound': 1.4019,\n",
       " 'mean_positive': 0.31,\n",
       " 'mean_negative': 0.0,\n",
       " 'mean_neutral': 0.69,\n",
       " 'positive_words': 1,\n",
       " 'negative_words': 0,\n",
       " 'neutral_words': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features(df.iloc[47,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unbalanced dataset\n",
    "features = [\n",
    "    (extract_features(df.text.iloc[i]), \"pro\")\n",
    "    for i in list(df[df.label=='pro'].index)\n",
    "]\n",
    "\n",
    "features.extend([\n",
    "    (extract_features(df.text.iloc[i]), \"anti\")\n",
    "    for i in list(df[df.label=='anti'].index)\n",
    "])\n",
    "\n",
    "features.extend([\n",
    "    (extract_features(df.text.iloc[i]), \"neutral\")\n",
    "    for i in list(df[df.label=='neutral'].index)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(features)\n",
    "train_count = int(len(features) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1570"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"SVCLinear\": SVC(kernel='linear'),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.61% - SVCLinear\n",
      "              anti  neutral  pro\n",
      "pred_anti        7        7    2\n",
      "pred_neutral     2      153   30\n",
      "pred_pro         0       67   46 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        anti      0.778     0.438     0.560        16\n",
      "     neutral      0.674     0.827     0.743       185\n",
      "         pro      0.590     0.407     0.482       113\n",
      "\n",
      "    accuracy                          0.656       314\n",
      "   macro avg      0.681     0.557     0.595       314\n",
      "weighted avg      0.649     0.656     0.639       314\n",
      " \n",
      "\n",
      "64.65% - KNeighborsClassifier\n",
      "              anti  neutral  pro\n",
      "pred_anti        8        2    6\n",
      "pred_neutral     5      127   53\n",
      "pred_pro         1       44   68 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        anti      0.571     0.500     0.533        16\n",
      "     neutral      0.734     0.686     0.709       185\n",
      "         pro      0.535     0.602     0.567       113\n",
      "\n",
      "    accuracy                          0.646       314\n",
      "   macro avg      0.614     0.596     0.603       314\n",
      "weighted avg      0.654     0.646     0.649       314\n",
      " \n",
      "\n",
      "64.65% - DecisionTreeClassifier\n",
      "              anti  neutral  pro\n",
      "pred_anti        7        4    5\n",
      "pred_neutral     3      138   44\n",
      "pred_pro         0       55   58 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        anti      0.700     0.438     0.538        16\n",
      "     neutral      0.701     0.746     0.723       185\n",
      "         pro      0.542     0.513     0.527       113\n",
      "\n",
      "    accuracy                          0.646       314\n",
      "   macro avg      0.648     0.566     0.596       314\n",
      "weighted avg      0.643     0.646     0.643       314\n",
      " \n",
      "\n",
      "68.15% - RandomForestClassifier\n",
      "              anti  neutral  pro\n",
      "pred_anti        8        3    5\n",
      "pred_neutral     3      147   35\n",
      "pred_pro         0       54   59 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        anti      0.727     0.500     0.593        16\n",
      "     neutral      0.721     0.795     0.756       185\n",
      "         pro      0.596     0.522     0.557       113\n",
      "\n",
      "    accuracy                          0.682       314\n",
      "   macro avg      0.681     0.606     0.635       314\n",
      "weighted avg      0.676     0.682     0.676       314\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, sklearn_classifier in classifiers.items():\n",
    "    classifier = nltk.classify.SklearnClassifier(sklearn_classifier)\n",
    "    classifier.train(features[:train_count])\n",
    "    accuracy = nltk.classify.accuracy(classifier, features[train_count:])\n",
    "    print(F\"{accuracy:.2%} - {name}\")\n",
    "    \n",
    "    # confusion matrix\n",
    "    true_labels = [label for features, label in features[train_count:]]\n",
    "    pred_labels = classifier.classify_many([features for features, label in features[train_count:]])\n",
    "    cm = pd.DataFrame(confusion_matrix(true_labels,pred_labels),columns=['anti','neutral','pro'],index=['pred_anti','pred_neutral','pred_pro'])\n",
    "    print(cm,'\\n')\n",
    "    \n",
    "    # classification report\n",
    "    print(metrics.classification_report(true_labels,pred_labels,digits=3),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersampled dataset\n",
    "undersampled_features = [\n",
    "    (extract_features(df.text.iloc[i]), \"pro\")\n",
    "    for i in list(df[df.label=='pro'].index)[:200]\n",
    "]\n",
    "\n",
    "undersampled_features.extend([\n",
    "    (extract_features(df.text.iloc[i]), \"anti\")\n",
    "    for i in list(df[df.label=='anti'].index)[:96]\n",
    "])\n",
    "\n",
    "undersampled_features.extend([\n",
    "    (extract_features(df.text.iloc[i]), \"neutral\")\n",
    "    for i in list(df[df.label=='neutral'].index)[:200]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(undersampled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(undersampled_features)\n",
    "train_count = len(undersampled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.68% - SVCLinear\n",
      "              anti  neutral  pro\n",
      "pred_anti       95        1    0\n",
      "pred_neutral   170      484  238\n",
      "pred_pro       117      107  358 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        anti      0.249     0.990     0.397        96\n",
      "     neutral      0.818     0.543     0.652       892\n",
      "         pro      0.601     0.615     0.608       582\n",
      "\n",
      "    accuracy                          0.597      1570\n",
      "   macro avg      0.556     0.716     0.553      1570\n",
      "weighted avg      0.702     0.597     0.620      1570\n",
      " \n",
      "\n",
      "62.93% - KNeighborsClassifier\n",
      "              anti  neutral  pro\n",
      "pred_anti       87        2    7\n",
      "pred_neutral    78      492  322\n",
      "pred_pro        47      126  409 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        anti      0.410     0.906     0.565        96\n",
      "     neutral      0.794     0.552     0.651       892\n",
      "         pro      0.554     0.703     0.620       582\n",
      "\n",
      "    accuracy                          0.629      1570\n",
      "   macro avg      0.586     0.720     0.612      1570\n",
      "weighted avg      0.681     0.629     0.634      1570\n",
      " \n",
      "\n",
      "69.24% - DecisionTreeClassifier\n",
      "              anti  neutral  pro\n",
      "pred_anti       90        6    0\n",
      "pred_neutral    42      598  252\n",
      "pred_pro        31      152  399 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        anti      0.552     0.938     0.695        96\n",
      "     neutral      0.791     0.670     0.726       892\n",
      "         pro      0.613     0.686     0.647       582\n",
      "\n",
      "    accuracy                          0.692      1570\n",
      "   macro avg      0.652     0.764     0.689      1570\n",
      "weighted avg      0.710     0.692     0.695      1570\n",
      " \n",
      "\n",
      "70.89% - RandomForestClassifier\n",
      "              anti  neutral  pro\n",
      "pred_anti       90        6    0\n",
      "pred_neutral    37      606  249\n",
      "pred_pro        21      144  417 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        anti      0.608     0.938     0.738        96\n",
      "     neutral      0.802     0.679     0.735       892\n",
      "         pro      0.626     0.716     0.668       582\n",
      "\n",
      "    accuracy                          0.709      1570\n",
      "   macro avg      0.679     0.778     0.714      1570\n",
      "weighted avg      0.725     0.709     0.711      1570\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, sklearn_classifier in classifiers.items():\n",
    "    classifier = nltk.classify.SklearnClassifier(sklearn_classifier)\n",
    "    classifier.train(undersampled_features)\n",
    "    accuracy = nltk.classify.accuracy(classifier, features)\n",
    "    print(F\"{accuracy:.2%} - {name}\")\n",
    "    \n",
    "    # confusion matrix\n",
    "    true_labels = [label for features, label in features]\n",
    "    pred_labels = classifier.classify_many([features for features, label in features])\n",
    "    cm = pd.DataFrame(confusion_matrix(true_labels,pred_labels),columns=['anti','neutral','pro'],index=['pred_anti','pred_neutral','pred_pro'])\n",
    "    print(cm,'\\n')\n",
    "    \n",
    "    # classification report\n",
    "    print(metrics.classification_report(true_labels,pred_labels,digits=3),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampled dataset\n",
    "oversampled_features = [\n",
    "    (extract_features(df.text.iloc[i]), \"pro\")\n",
    "    for i in list(df[df.label=='pro'].index)\n",
    "]\n",
    "\n",
    "for x in range(5):\n",
    "    oversampled_features.extend([\n",
    "        (extract_features(df.text.iloc[i]), \"anti\")\n",
    "        for i in list(df[df.label=='anti'].index)\n",
    "    ])\n",
    "\n",
    "oversampled_features.extend([\n",
    "    (extract_features(df.text.iloc[i]), \"neutral\")\n",
    "    for i in list(df[df.label=='neutral'].index)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1954"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oversampled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(oversampled_features)\n",
    "train_count = int(len(oversampled_features) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.45% - SVCLinear\n",
      "              anti  neutral  pro\n",
      "pred_anti       84        1    0\n",
      "pred_neutral    29      126    9\n",
      "pred_pro        33       67   42 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        anti     0.5753    0.9882    0.7273        85\n",
      "     neutral     0.6495    0.7683    0.7039       164\n",
      "         pro     0.8235    0.2958    0.4352       142\n",
      "\n",
      "    accuracy                         0.6445       391\n",
      "   macro avg     0.6828    0.6841    0.6221       391\n",
      "weighted avg     0.6966    0.6445    0.6114       391\n",
      " \n",
      "\n",
      "68.03% - KNeighborsClassifier\n",
      "              anti  neutral  pro\n",
      "pred_anti       81        0    4\n",
      "pred_neutral    11      112   41\n",
      "pred_pro         9       60   73 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        anti     0.8020    0.9529    0.8710        85\n",
      "     neutral     0.6512    0.6829    0.6667       164\n",
      "         pro     0.6186    0.5141    0.5615       142\n",
      "\n",
      "    accuracy                         0.6803       391\n",
      "   macro avg     0.6906    0.7167    0.6997       391\n",
      "weighted avg     0.6721    0.6803    0.6729       391\n",
      " \n",
      "\n",
      "70.59% - DecisionTreeClassifier\n",
      "              anti  neutral  pro\n",
      "pred_anti       81        4    0\n",
      "pred_neutral     7      118   39\n",
      "pred_pro         1       64   77 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        anti     0.9101    0.9529    0.9310        85\n",
      "     neutral     0.6344    0.7195    0.6743       164\n",
      "         pro     0.6638    0.5423    0.5969       142\n",
      "\n",
      "    accuracy                         0.7059       391\n",
      "   macro avg     0.7361    0.7382    0.7341       391\n",
      "weighted avg     0.7050    0.7059    0.7020       391\n",
      " \n",
      "\n",
      "72.63% - RandomForestClassifier\n",
      "              anti  neutral  pro\n",
      "pred_anti       78        7    0\n",
      "pred_neutral     4      130   30\n",
      "pred_pro         1       65   76 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        anti     0.9398    0.9176    0.9286        85\n",
      "     neutral     0.6436    0.7927    0.7104       164\n",
      "         pro     0.7170    0.5352    0.6129       142\n",
      "\n",
      "    accuracy                         0.7263       391\n",
      "   macro avg     0.7668    0.7485    0.7506       391\n",
      "weighted avg     0.7346    0.7263    0.7224       391\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, sklearn_classifier in classifiers.items():\n",
    "    classifier = nltk.classify.SklearnClassifier(sklearn_classifier)\n",
    "    classifier.train(oversampled_features[:train_count])\n",
    "    accuracy = nltk.classify.accuracy(classifier, oversampled_features[train_count:])\n",
    "    print(F\"{accuracy:.2%} - {name}\")\n",
    "    \n",
    "    # confusion matrix\n",
    "    true_labels = [label for features, label in oversampled_features[train_count:]]\n",
    "    pred_labels = classifier.classify_many([features for features, label in oversampled_features[train_count:]])\n",
    "    cm = pd.DataFrame(confusion_matrix(true_labels,pred_labels),columns=['anti','neutral','pro'],index=['pred_anti','pred_neutral','pred_pro'])\n",
    "    print(cm,'\\n')\n",
    "    \n",
    "    # classification report\n",
    "    print(metrics.classification_report(true_labels,pred_labels,digits=4),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.12% - Random Forest Classifier\n",
      "\n",
      "              anti  neutral  pro\n",
      "pred_anti       78        7    0\n",
      "pred_neutral     4      129   31\n",
      "pred_pro         1       66   75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        anti      0.940     0.918     0.929        85\n",
      "     neutral      0.639     0.787     0.705       164\n",
      "         pro      0.708     0.528     0.605       142\n",
      "\n",
      "    accuracy                          0.721       391\n",
      "   macro avg      0.762     0.744     0.746       391\n",
      "weighted avg      0.729     0.721     0.717       391\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf = nltk.classify.SklearnClassifier(RandomForestClassifier())\n",
    "rf_clf.train(oversampled_features[:train_count])\n",
    "accuracy = nltk.classify.accuracy(rf_clf, oversampled_features[train_count:])\n",
    "print(F\"{accuracy:.2%} - Random Forest Classifier\\n\")\n",
    "\n",
    "true_labels = [label for features, label in oversampled_features[train_count:]]\n",
    "pred_labels = rf_clf.classify_many([features for features, label in oversampled_features[train_count:]])\n",
    "cm = pd.DataFrame(confusion_matrix(true_labels,pred_labels),columns=['anti','neutral','pro'],index=['pred_anti','pred_neutral','pred_pro'])\n",
    "print(cm)\n",
    "\n",
    "print(metrics.classification_report(true_labels,pred_labels,digits=3),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>ref_type</th>\n",
       "      <th>ref_tweet_text</th>\n",
       "      <th>ref_author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1319419539420053506</td>\n",
       "      <td>RT @jessicaramos: Have you gotten your flu sho...</td>\n",
       "      <td>retweet</td>\n",
       "      <td>Have you gotten your flu shot yet? I stopped b...</td>\n",
       "      <td>26583978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1319412029317414913</td>\n",
       "      <td>@cbreezy220 Lol my company just ended our offi...</td>\n",
       "      <td>replied</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1319404343603482625</td>\n",
       "      <td>RT @jessicaramos: Have you gotten your flu sho...</td>\n",
       "      <td>retweet</td>\n",
       "      <td>Have you gotten your flu shot yet? I stopped b...</td>\n",
       "      <td>26583978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1319402845741875200</td>\n",
       "      <td>RT @jessicaramos: Have you gotten your flu sho...</td>\n",
       "      <td>retweet</td>\n",
       "      <td>Have you gotten your flu shot yet? I stopped b...</td>\n",
       "      <td>26583978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1319400472273444865</td>\n",
       "      <td>@ethanjweiss @TheSkeptic21 @drjohnm We are all...</td>\n",
       "      <td>replied</td>\n",
       "      <td>@TheSkeptic21 @drjohnm This ☝️</td>\n",
       "      <td>95292805.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0  1319419539420053506  RT @jessicaramos: Have you gotten your flu sho...   \n",
       "1  1319412029317414913  @cbreezy220 Lol my company just ended our offi...   \n",
       "2  1319404343603482625  RT @jessicaramos: Have you gotten your flu sho...   \n",
       "3  1319402845741875200  RT @jessicaramos: Have you gotten your flu sho...   \n",
       "4  1319400472273444865  @ethanjweiss @TheSkeptic21 @drjohnm We are all...   \n",
       "\n",
       "  ref_type                                     ref_tweet_text  ref_author_id  \n",
       "0  retweet  Have you gotten your flu shot yet? I stopped b...     26583978.0  \n",
       "1  replied                                                NaN            NaN  \n",
       "2  retweet  Have you gotten your flu shot yet? I stopped b...     26583978.0  \n",
       "3  retweet  Have you gotten your flu shot yet? I stopped b...     26583978.0  \n",
       "4  replied                     @TheSkeptic21 @drjohnm This ☝️     95292805.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets = pd.read_csv('complete_tweets.csv',index_col=0)\n",
    "all_tweets.reset_index(drop=True, inplace=True)\n",
    "all_tweets = all_tweets[['id','text','ref_type','ref_tweet_text','ref_author_id']]\n",
    "all_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lazarus/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def text_preprocessing(s):\n",
    "    \n",
    "    s = s.lower()\n",
    "    # Remove non-English characters\n",
    "    s = re.sub(r'[^\\x00-\\x7F]+', ' ', s)\n",
    "    # Change 't to 'not'\n",
    "    s = re.sub(r\"\\'t\", \" not\", s)\n",
    "    # Remove @name\n",
    "    s = re.sub(r'(@.*?)[\\s]', '', s)\n",
    "    # Remove websites\n",
    "    s = re.sub(r'http\\S+', '', s)\n",
    "    # Standardise 'covid'\n",
    "    s = re.sub(r'(covid\\-\\w+|covid\\w+|covid\\s(19))', 'covid', s)\n",
    "    # Isolate and remove punctuations\n",
    "    s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\\\\\/\\,])', r' \\1 ', s)\n",
    "    s = re.sub(r'[^\\w\\s]', ' ', s)\n",
    "    # Remove some special characters\n",
    "    s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
    "    # Remove stopwords except 'not' and 'can'\n",
    "    s = \" \".join([word for word in s.split()\n",
    "                  if word not in stopwords.words('english')\n",
    "                  or word in ['not', 'can']])\n",
    "    # Remove numbers\n",
    "    s = re.sub(r'\\d(th)|\\d', '', s)\n",
    "    # Remove trailing whitespace\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_tweets)):\n",
    "    if all_tweets.ref_type[i] == 'retweet':\n",
    "        if isinstance(all_tweets.ref_tweet_text[i], str): # some retweets do not have ref_tweet_text, i.e. 'nan'\n",
    "            all_tweets.text[i] = all_tweets.ref_tweet_text[i] # replace retweets with the ref_tweet_text\n",
    "    elif all_tweets.ref_type[i] == 'replied':\n",
    "        try: \n",
    "            all_tweets.text[i] = all_tweets.text[i] + all_tweets.ref_tweet_text[i]\n",
    "        except: # some replied tweets do not have a ref_tweet_text\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>ref_author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1319419539420053506</td>\n",
       "      <td>Have you gotten your flu shot yet? I stopped b...</td>\n",
       "      <td>26583978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1319412029317414913</td>\n",
       "      <td>@cbreezy220 Lol my company just ended our offi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1319404343603482625</td>\n",
       "      <td>Have you gotten your flu shot yet? I stopped b...</td>\n",
       "      <td>26583978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1319402845741875200</td>\n",
       "      <td>Have you gotten your flu shot yet? I stopped b...</td>\n",
       "      <td>26583978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1319400472273444865</td>\n",
       "      <td>@ethanjweiss @TheSkeptic21 @drjohnm We are all...</td>\n",
       "      <td>95292805.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0  1319419539420053506  Have you gotten your flu shot yet? I stopped b...   \n",
       "1  1319412029317414913  @cbreezy220 Lol my company just ended our offi...   \n",
       "2  1319404343603482625  Have you gotten your flu shot yet? I stopped b...   \n",
       "3  1319402845741875200  Have you gotten your flu shot yet? I stopped b...   \n",
       "4  1319400472273444865  @ethanjweiss @TheSkeptic21 @drjohnm We are all...   \n",
       "\n",
       "   ref_author_id  \n",
       "0     26583978.0  \n",
       "1            NaN  \n",
       "2     26583978.0  \n",
       "3     26583978.0  \n",
       "4     95292805.0  "
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets = all_tweets.drop(['ref_tweet_text','ref_type'],axis=1)\n",
    "all_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>ref_author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1319419539420053506</td>\n",
       "      <td>gotten flu shot yet stopped plaza del sol fami...</td>\n",
       "      <td>26583978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1319412029317414913</td>\n",
       "      <td>lol company ended office lease nyc plans signi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1319404343603482625</td>\n",
       "      <td>gotten flu shot yet stopped plaza del sol fami...</td>\n",
       "      <td>26583978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1319402845741875200</td>\n",
       "      <td>gotten flu shot yet stopped plaza del sol fami...</td>\n",
       "      <td>26583978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1319400472273444865</td>\n",
       "      <td>together love effort sf nyc unless everyone le...</td>\n",
       "      <td>95292805.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0  1319419539420053506  gotten flu shot yet stopped plaza del sol fami...   \n",
       "1  1319412029317414913  lol company ended office lease nyc plans signi...   \n",
       "2  1319404343603482625  gotten flu shot yet stopped plaza del sol fami...   \n",
       "3  1319402845741875200  gotten flu shot yet stopped plaza del sol fami...   \n",
       "4  1319400472273444865  together love effort sf nyc unless everyone le...   \n",
       "\n",
       "   ref_author_id  \n",
       "0     26583978.0  \n",
       "1            NaN  \n",
       "2     26583978.0  \n",
       "3     26583978.0  \n",
       "4     95292805.0  "
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets_preprocessed = all_tweets\n",
    "all_tweets_preprocessed['text'] = all_tweets_preprocessed['text'].astype(str)\n",
    "all_tweets_preprocessed['text'] = [text_preprocessing(text) for text in all_tweets_preprocessed['text']]\n",
    "all_tweets_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270394"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tweets_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove tweets under five words\n",
    "for i in range(len(all_tweets_preprocessed)):\n",
    "    tweet = all_tweets_preprocessed.text[i]\n",
    "    if len(tweet.split()) < 5:\n",
    "        all_tweets_preprocessed.drop(i, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_preprocessed.to_csv('all_tweets_preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [\n",
    "    (extract_features(all_tweets_preprocessed.text.iloc[i]))\n",
    "    for i in range(len(all_tweets_preprocessed))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>ref_author_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1319419539420053506</td>\n",
       "      <td>gotten flu shot yet stopped plaza del sol fami...</td>\n",
       "      <td>26583978.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1319412029317414913</td>\n",
       "      <td>lol company ended office lease nyc plans signi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1319404343603482625</td>\n",
       "      <td>gotten flu shot yet stopped plaza del sol fami...</td>\n",
       "      <td>26583978.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1319402845741875200</td>\n",
       "      <td>gotten flu shot yet stopped plaza del sol fami...</td>\n",
       "      <td>26583978.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1319400472273444865</td>\n",
       "      <td>together love effort sf nyc unless everyone le...</td>\n",
       "      <td>95292805.0</td>\n",
       "      <td>anti</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0  1319419539420053506  gotten flu shot yet stopped plaza del sol fami...   \n",
       "1  1319412029317414913  lol company ended office lease nyc plans signi...   \n",
       "2  1319404343603482625  gotten flu shot yet stopped plaza del sol fami...   \n",
       "3  1319402845741875200  gotten flu shot yet stopped plaza del sol fami...   \n",
       "4  1319400472273444865  together love effort sf nyc unless everyone le...   \n",
       "\n",
       "   ref_author_id    label  \n",
       "0     26583978.0  neutral  \n",
       "1            NaN  neutral  \n",
       "2     26583978.0  neutral  \n",
       "3     26583978.0  neutral  \n",
       "4     95292805.0     anti  "
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = rf_clf.classify_many(all_features)\n",
    "all_tweets['label'] = pred\n",
    "all_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pro count: 87099\n",
      "anti count: 16837\n",
      "neutral count: 159504\n"
     ]
    }
   ],
   "source": [
    "for label in ['pro','anti','neutral']:\n",
    "    print(label,'count:',len(all_tweets[all_tweets.label==label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets.to_csv('all_tweets_labelled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263440"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
